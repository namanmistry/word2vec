{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7872df4-2eb7-4376-aa12-a908d34349ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('Data/training.1600000.processed.noemoticon.csv','r',encoding='latin-1') as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7517f24a-4c4d-4756-8ca8-81ff72a5a371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eada96a2-f3f8-45d2-ac10-3d7b5b1a4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['0','1','2','3','4','5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6949701d-9166-42b8-83b3-8011ec61539e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['5'] = data['5'].apply(lambda x: x.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3540a33c-2e47-47c5-b693-a5629f24b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['5'] = data['5'].apply(lambda x: [ i for i in x if len(i) >= 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ef7669-1506-4402-bc64-af611422c6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mangaaa I hope they will increase the capacity fast, yesterday was such a pain',\n",
       " ' Got the fail whale +15 times in 2 hours']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['5'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f094158f-dc58-424a-a46d-3c44e1d1ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import concurrent\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import psutil\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class EnglishDataCleaning:\n",
    "    def __init__(self,eng_data,save=False,name=None):\n",
    "        self.save = save\n",
    "        self.eng_data = eng_data\n",
    "        self.name = name\n",
    "    # this is normal cleaning method not using multiple cores\n",
    "    def clean(self,data):\n",
    "        result = []\n",
    "        for i in tqdm(data):\n",
    "            text = i\n",
    "            stop_words = stopwords.words('english')\n",
    "            final_str = []\n",
    "            regular_ex = r'[^a-zA-Z0-9\\s]'\n",
    "            regular_ex_1 = r'[$\\n]'\n",
    "            text = text.lower()\n",
    "            text = re.sub(regular_ex,'',text)\n",
    "            text = re.sub(regular_ex_1,'',text)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tokenization = nltk.word_tokenize(text)\n",
    "            for w in tokenization:\n",
    "                w = contractions.fix(w)\n",
    "                if w not in stop_words:\n",
    "                    final_str.append(lemmatizer.lemmatize(w))\n",
    "            result.append(' '.join(final_str))\n",
    "        try:\n",
    "            return result\n",
    "        finally:\n",
    "            if self.save == True:\n",
    "                with open(f'cleaned_eng_data_{self.name}','wb') as f:\n",
    "                    pickle.dump(result,f)\n",
    "                print(\"Data saved successfully...\")\n",
    "            \n",
    "    \n",
    "    # method using multiple cores\n",
    "    def fast_cleaning(self,data):\n",
    "        def init_worker(mps, fps, cut):\n",
    "            memorizedPaths, filepaths, cutoff = mps, fps, cut\n",
    "            DG = 1\n",
    "        def clean(text):\n",
    "            import contractions\n",
    "            from nltk.stem import WordNetLemmatizer\n",
    "            from nltk.corpus import stopwords\n",
    "            import re\n",
    "            import nltk\n",
    "\n",
    "            stop_words = stopwords.words('english')\n",
    "            final_str = []\n",
    "            regular_ex = r'[^a-zA-Z0-9\\s]'\n",
    "            regular_ex_1 = r'[$\\n]'\n",
    "            text = text.lower()\n",
    "            text = re.sub(regular_ex,'',text)\n",
    "            text = re.sub(regular_ex_1,'',text)\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            tokenization = nltk.word_tokenize(text)\n",
    "            for w in tokenization:\n",
    "                w = contractions.fix(w)\n",
    "                if w not in stop_words:\n",
    "                    final_str.append(lemmatizer.lemmatize(w))\n",
    "            return ' '.join(final_str)\n",
    "        try:\n",
    "            result = Parallel(n_jobs=-1, prefer=\"processes\", verbose=6)(\n",
    "            delayed(clean)(i) for i in tqdm(data))\n",
    "        finally:\n",
    "            if self.save == True:\n",
    "                with open(f'cleaned_eng_data_{self.name}','wb') as f:\n",
    "                    pickle.dump(result,f)\n",
    "                print(\"Data saved successfully...\")\n",
    "\n",
    "    def partial_hindi_cleaner(self,hin_data):\n",
    "        print(\"Cleaning hindi data...\")\n",
    "        cleaned_hin_data = []\n",
    "        for i in tqdm(range(len(hin_data))):\n",
    "            text = hin_data[i]\n",
    "            t = \"\"\n",
    "            regular_ex_1 = r'[$\\n]'\n",
    "            regular_ex_2 = r'[a-zA-Z]'\n",
    "            text = re.sub(regular_ex_1,'',text)\n",
    "            text = re.sub(regular_ex_2,'',text)\n",
    "            for c in text:\n",
    "                if c not in string.punctuation:\n",
    "                    t += c\n",
    "            cleaned_hin_data.append(t)\n",
    "        if self.save == True:\n",
    "            with open(f'cleaned_hin_data_{self.name}','wb') as f:\n",
    "                pickle.dump(cleaned_hin_data,f)\n",
    "            print(\"Data saved successfully\")\n",
    "        return cleaned_hin_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2155611f-83f6-49d2-97d8-d8f8afd37bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for i in data['5']:\n",
    "    for j in i:\n",
    "        new_data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f73abf-9b8c-4e44-ae33-4129d4a8890c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "507e5a70-a17c-4867-b447-52ba575ad0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = EnglishDataCleaning(new_data,save=True,name=\"english_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef217e-9135-4e91-83c6-f79a3081115b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a29066e9e8043fdb681c03ae144c24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2604061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2104 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 16568 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 34104 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 54968 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 78904 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=-1)]: Done 106168 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 136504 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 170168 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 206904 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 246968 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 290104 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 336568 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 386104 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 438968 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 494904 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 554168 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 616504 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 682168 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 750904 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 822968 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 898104 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 976568 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1058104 tasks      | elapsed:  4.2min\n"
     ]
    }
   ],
   "source": [
    "data_clean.fast_cleaning(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac5e12-345e-4f8b-9e90-8ccfe2f7abb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb5e34-7c5c-4214-a266-fa84c3c06969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7203573-f614-4a4e-b98d-de32b8735d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75ba78-3e5c-411f-a15f-9a6ebf619473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf2b6cf-75fe-408b-aca9-b5aeb668050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1239f1b8-aa52-4f59-9adc-9a42b55bea15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c837d0e605ed45b0b66aec9510ad3615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2604061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\multiprocess\\pool.py:851\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 851\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mp_tqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m p_map\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocess\u001b[38;5;241m.\u001b[39mPool(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_the_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tqdm\\notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\multiprocess\\pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mc:\\users\\naman\\appdata\\local\\programs\\python\\python38\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc80c8f-27d3-47df-aabb-e1217fa15f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe4e05-f5ed-43c4-b9f7-b26401a53fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d297d091-3ad0-49c8-a162-ad100c1d41b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cabe02181b94a2ba957da26717551ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2604061 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(len(new_data))):\n",
    "    new_data[i] = clean_the_data(new_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd8dd4-bdf7-46fb-afa2-13d20d941ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd08f0f-d8f1-431e-9c17-5aa7a65c123c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e72d347b-1357-4bb1-bf43-6b9f7f471671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@mangaaa I hope they will increase the capacity fast, yesterday was such a pain',\n",
       " ' Got the fail whale +15 times in 2 hours']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.eng_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366b1c9-febc-423f-a0b9-ab26e4ce9d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers Kernel",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
